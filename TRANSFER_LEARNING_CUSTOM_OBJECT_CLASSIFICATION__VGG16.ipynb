{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING FOR CUSTOM OBJECT CLASSIFICATION (VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explain step by step how to train a Custom Object Classifier, specifically a Sunflower Classifier that will learn to recognize the presence of sunflowers in new images.   \n",
    "In order to achieve this goal, we will apply Transfer Learning techniques starting from a pre-trained VGG16 architecture and we will train our Custom Classifier on our own dataset (containing 50% images with sunflowers and 50% images without).   \n",
    "Furthermore, the training involves GPUs (because they are much more efficient to train Neural Networks) and it is distributed across multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "We import Tensorflow, Keras, Pandas, Numpy, metrics from Sklearn, Matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, Model \n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, f1_score, auc\n",
    "from numpy import argmax\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs check\n",
    "\n",
    "First of all, let's check for available GPUs and choose the number of GPUs to use for distribute training.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For istance, let's assume we have 2 GPUs and we want to use them all to perform our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 2      # set number of GPUS to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading train, validation and test CSV\n",
    "\n",
    "We need to load 3 csv (train, validation and test csv) and each of them must include the following 2 columns:\n",
    "- \"Filenames\" (image filename),\n",
    "- \"labels\" (associated label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING TRAIN, VALIDATION AND TEST csv ##\n",
    "############################################\n",
    "\n",
    "path_csv = \"/pasquale/CUSTOM_OBJECT_CLASSIFICATION_VGG16/\"                 # loading path\n",
    "\n",
    "df_train = pd.read_csv(path_csv + \"train.csv\", sep= \";\")                   # read train.csv\n",
    "\n",
    "df_validation = pd.read_csv(path_csv + \"validation.csv\", sep = \";\")        # read validation.csv\n",
    "\n",
    "df_test = pd.read_csv(path_csv + \"test.csv\", sep= \";\")                     # read test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention: df_train, df_validation and df_test must be in this format !!!   \n",
    "We can see that \"labels\" column in the dataframe shows:\n",
    "- a list containing \"sunflower\" when the object is present in the image\n",
    "- an empty list when the object is not present in the image\n",
    "![title](csv_format_custom_object_classification.png)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation \n",
    "### (Rotating, Shifting, Zooming, Flipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation is a technique to increase the amount of relevant data in our dataset. This will allow us to train our neural network with additional synthetically modified data.     \n",
    "Data augmentation is useful to improve performance and outcomes of deep learning models by forming new and different examples, starting from the original ones.   \n",
    "We use ImageDataGenerator to perform real-time training data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING DATA AUGMENTATION ##\n",
    "################################\n",
    "\n",
    "## Data Augmentation is performed only on training images\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale = 1./255.,                   # rescaling factor\n",
    "                    rotation_range = 40,                 # degree range for random rotations\n",
    "                    width_shift_range = 0.2,             # range random width shift \n",
    "                    height_shift_range = 0.2,            # range random height shift\n",
    "                    shear_range = 0.2,                   # shear intensity\n",
    "                    zoom_range = 0.1,                    # range for random zoom\n",
    "                    horizontal_flip = True,              # randomly flip inputs horizontally\n",
    "                    fill_mode = \"nearest\"                # how to fill points outside the boundaries\n",
    "                    )\n",
    "\n",
    "# No augmentation in validation data\n",
    "valid_datagen = ImageDataGenerator( rescale = 1./255. )\n",
    "\n",
    "# No augmentation in test data\n",
    "test_datagen = ImageDataGenerator( rescale = 1./255. )\n",
    "\n",
    "\n",
    "\n",
    "# Flow training images from train dataframe in batches using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                                        \n",
    "        dataframe = df_train,                      # dataframe with filenames and labels\n",
    "        directory = '/pasquale/CUSTOM_OBJECT_CLASSIFICATION_VGG16/TRAIN',    # directory train images\n",
    "        x_col = \"Filenames\",                       # name of the column which contains the filenames of the images\n",
    "        y_col = \"labels\",                          # name of the column which contains the class name\n",
    "        batch_size = 32 * num_gpus,                # size of the batch\n",
    "        seed = 42,                                 # set seed for reproducible results\n",
    "        shuffle = True,                            # shuffle images\n",
    "        class_mode = \"categorical\",                # class mode\n",
    "        #classes = [\"sunflower\"],                  # class name\n",
    "        target_size = (224, 224),                  # size of image\n",
    "        )\n",
    "\n",
    "# Flow validation images from validation dataframe in batches using valid_datagen generator\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "\n",
    "        dataframe = df_test,\n",
    "        directory = '/pasquale/CUSTOM_OBJECT_CLASSIFICATION_VGG16/VALIDATION', # directory validation images\n",
    "        x_col = \"Filenames\",\n",
    "        y_col = \"labels\",\n",
    "        batch_size = 32 * num_gpus,\n",
    "        seed = 42,\n",
    "        shuffle = True,      \n",
    "        class_mode = \"categorical\",\n",
    "        #classes = [\"sunflower\"],\n",
    "        target_size = (224, 224)\n",
    "        )\n",
    "\n",
    "# Flow test images from test dataframe in batches using test_datagen generator\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    \n",
    "        dataframe = df_test,\n",
    "        directory = '/pasquale/CUSTOM_OBJECT_CLASSIFICATION_VGG16/TEST',   # directory test images\n",
    "        x_col = \"Filenames\",\n",
    "        y_col = None,\n",
    "        batch_size = 32 * num_gpus,\n",
    "        seed = 42,\n",
    "        shuffle = False,     # PAY ATTENTION: SHUFFLE = FALSE in the test data, because\n",
    "                                        # we need to yield the images in “order”, \n",
    "                                        # to predict the outputs and match them with their unique filenames\n",
    "        class_mode = None,\n",
    "        target_size = (224,224)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define the size of the steps for training, validation and test.     \n",
    "The step is defined as the ratio between the number of images (in the specific set) and the batch size (in the specific set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining STEP SIZE \n",
    "STEP_SIZE_TRAIN = train_generator.n/train_generator.batch_size     # step size training\n",
    "STEP_SIZE_VALID = valid_generator.n/valid_generator.batch_size     # step size validation\n",
    "STEP_SIZE_TEST = test_generator.n/test_generator.batch_size        # step size test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building (Transfer Learning) and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build our Custom Classifier we will use the VGG16 architecture, that is a network pre-trained on a large dataset (ImageNet dataset).    \n",
    "Such a network would have already learned features that are useful for most computer vision problems, and leveraging such features would allow us to reach a better performance than any method that would only rely on the available data.\n",
    "\n",
    "Let's first have a look at VGG16 architecture:\n",
    "\n",
    "![title](VGG16.png) \n",
    "\n",
    "In order to build our Custom Model, we take only the Convolutional Layers from this architecture and we add our custom Fully Connected Layers on top of Convolutional part of VGG16 architecture.     \n",
    "Then, we freeze the entire Convolutional block (that works as features extractor) and we make predictions by training only the Fully Connected Layers on our own dataset.   \n",
    "The Last Layer of our Custom Classifier contains a single node (1 class) with sigmoid activation function to output probability of sunflower for each specific example (image).   \n",
    "The technique described above is known as \"Transfer Learning\", applied to Image Classification task. \n",
    "\n",
    "As Keras documentation well explains:   \n",
    "\n",
    "\"Transfer Learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. Transfer Learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.   \n",
    "The most common incarnation of Transfer Learning in the context of deep learning is the following workflow:\n",
    "\n",
    "    - Take layers from a previously trained model.\n",
    "    - Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
    "    - Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into\n",
    "      predictions on a new dataset.\n",
    "    - Train the new layers on your dataset.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MirroredStrategy() is used for synchronous distributed training on multiple GPUs\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()        # all GPUs involved\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    ## VGG16 MODEL LOADING ##\n",
    "    #########################\n",
    "    \n",
    "    vgg16_model = VGG16(\n",
    "                     include_top = False,              # Leave out the 3 fully connected layers\n",
    "                     weights = 'imagenet'              # Pre-trained weights on Imagenet dataset\n",
    "                     )\n",
    "    \n",
    "    ## FREEZING CONVOLUTIONAL BLOCKS ##\n",
    "    ###################################\n",
    "    \n",
    "    for layer in vgg16_model.layers:                   # make NON-TRAINABLE LAYERS\n",
    "        layer.trainable = False\n",
    "        \n",
    "    \n",
    "    ## CREATE CLASSIFICATION HEAD ON TOP OF VGG16 MODEL ##\n",
    "    ######################################################\n",
    "    \n",
    "    # Create Input Layer\n",
    "    input_layer = Input(shape=(224, 224, 3), name = 'input')\n",
    "\n",
    "    # Generate output from VGG16 convolutional block \n",
    "    output_vgg16_model = vgg16_model(input_layer)\n",
    "\n",
    "    # Add the Fully-Connected Layers \n",
    "    x = Flatten(name = 'flatten')(output_vgg16_model)                  # Flatten\n",
    "    x = Dense(4096, activation='relu', name = 'fc1')(x)                # 1st FCLayer\n",
    "    x = layers.Dropout(0.4)(x)                                         # Dropout\n",
    "    x = Dense(4096, activation='relu', name = 'fc2')(x)                # 2nd FCLayer\n",
    "    x = layers.Dropout(0.4)(x)                                         # Dropout\n",
    "    x = Dense(1, activation = 'sigmoid', name = 'predictions')(x)      # Output Layer\n",
    "\n",
    "    #Create Custom Model  \n",
    "    final_vgg16_model = Model(inputs = input_layer, outputs = x)\n",
    "    \n",
    "    \n",
    "    ## PARAMETERS AND METRICS SETTING ##\n",
    "    ####################################\n",
    "    \n",
    "    # metrics\n",
    "    precision = tf.keras.metrics.Precision(name = \"precision\")                               # precision\n",
    "    recall = tf.keras.metrics.Recall(name = \"recall\")                                        # recall\n",
    "    f1_score = tfa.metrics.F1Score(num_classes =  1, threshold = 0.5, name = 'f1_score')     # f1 score\n",
    "    auc = tf.keras.metrics.AUC(name = \"auc\")                                                 # AUC\n",
    "    tp = tf.keras.metrics.TruePositives(name='tp')                                           # True Positives\n",
    "    fp = tf.keras.metrics.FalsePositives(name='fp')                                          # False Positives\n",
    "    tn = tf.keras.metrics.TrueNegatives(name='tn')                                           # True Negatives\n",
    "    fn = tf.keras.metrics.FalseNegatives(name='fn')                                          # False Negatives\n",
    "    \n",
    "    \n",
    "    # Define EARLY STOPPING  (we monitor validation f1 score)\n",
    "    early_stopping = EarlyStopping(\n",
    "                            monitor = \"val_f1_score\",       # metric to be monitored\n",
    "                            mode = \"max\",                   # stop when the quantity monitored has stopped increasing\n",
    "                            restore_best_weights = True,    # restore weights from the epoch with the best value \n",
    "                                                            # of monitored quantity\n",
    "                            patience = 50                   # wait 50 epochs without improving validation f1_score\n",
    "                            )                  \n",
    "    \n",
    "    \n",
    "    # Define MODEL CHECKPOINT\n",
    "    # ModelCheckpoint allows us to save the best model with the best weights during the training.\n",
    "    # The best model observed during training is defined by a chosen performance metric on the validation dataset.\n",
    "    mc = ModelCheckpoint(\n",
    "                          'sunflower_classifier_best.h5',  # model saving name\n",
    "                           monitor = 'val_f1_score',       # metric to be monitored\n",
    "                           mode = 'max',                   # increasing value of the metric\n",
    "                           verbose = 1,                    # verbose mode\n",
    "                           save_best_only = True           # save only the model that has achieved the best performance\n",
    "                         )\n",
    "    \n",
    "    \n",
    "    # Adam Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "                           learning_rate=0.001 * num_gpus)\n",
    "\n",
    "    \n",
    "    ## COMPILE THE MODEL ##\n",
    "    #######################\n",
    "    \n",
    "    final_vgg16_model.compile( \n",
    "                       optimizer = optimizer,                                                     # optimizer\n",
    "                       loss = 'binary_crossentropy',                                              # loss function\n",
    "                       metrics = [\"accuracy\", precision, recall, f1_score, auc, fp, tp, fn, tn]   # metrics\n",
    "                        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## MODEL TRAINING ##\n",
    "    ####################\n",
    "\n",
    "    history_vgg16 = final_vgg16_model.fit(\n",
    "                            \n",
    "                            train_generator,                    # train generator with images and labels\n",
    "                            steps_per_epoch = STEP_SIZE_TRAIN,  # total number of steps (batches of samples)... \n",
    "                                                                # ...before declaring one epoch finished\n",
    "                            validation_data = valid_generator,  # validation generator with images and labels\n",
    "                            validation_steps = STEP_SIZE_VALID, # validation step\n",
    "                            epochs = 500,                       # number of training epochs\n",
    "                            callbacks = [early_stopping, mc]    # callbacks\n",
    "                            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training and Validation Metrics\n",
    "### (Model Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the Classifier, we can have a first look at the perfomance of our model by comparing training and validation metrics (loss, precision, recall, f1 score).     \n",
    "For istance, a low training loss and a high validation loss can be interpreted as a sign of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS\n",
    "plt.plot(history_vgg16.history['loss'], label='train loss')\n",
    "plt.plot(history_vgg16.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# RECALL\n",
    "plt.plot(history_vgg16.history['recall'], label='train recall')\n",
    "plt.plot(history_vgg16.history['val_recall'], label='validation recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PRECISION\n",
    "plt.plot(history_vgg16.history['precision'], label='train precision')\n",
    "plt.plot(history_vgg16.history['val_precision'], label='validation precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# F1-SCORE \n",
    "plt.plot(history_vgg16.history['f1_score'], label='train f1_score')\n",
    "plt.plot(history_vgg16.history['val_f1_score'], label='validation f1_score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's analize in detail how our Custom Classifier performs on test data by making predictions on brand new images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()       # reset test generator\n",
    "\n",
    "threshold = 0.5              # threshold to distinguish between positive (1) and negative class (0)\n",
    "\n",
    "# predict probabilities for test images\n",
    "pred_prob = final_vgg16_model.predict(\n",
    "                            \n",
    "                            test_generator,               # images in test generator\n",
    "                            steps = STEP_SIZE_TEST,       # step size\n",
    "                            verbose=1                     # verbose\n",
    "                            )\n",
    "\n",
    "# predict class for test images\n",
    "y_pred = (pred_prob > threshold).astype(int)              # convert probabilities into predicted classes\n",
    "\n",
    "\n",
    "# extract ground truth labels from test images\n",
    "y_true = []\n",
    "for i in df_test.labels:\n",
    "    if \"sunflower\" in i:\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Classifier Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate in detail the performance of our Custom Classifier by having a look at the Confusion Matrix, which allows us to clearly compare actual and predicted labels. Indeed, we can appreciate True Positives, True Negatives, False Positives and False Negatives values.   \n",
    "Furthermore, Classification Report also helps us in evaluating Precision, Recall and F1 score of our model in both images with sunflowers and images without sunflowers.    \n",
    "All metrics will guide our decisions to fine-tune the parameters of our model in order to achieve the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFUSION MATRIX ##\n",
    "######################\n",
    "\n",
    "SUNFLOWER_CONFUSION_MATRIX = pd.DataFrame(\n",
    "                 \n",
    "                 confusion_matrix(y_true, y_pred), \n",
    "                 columns = [\"NO_SUNFLOWER_pred\",\"SUNFLOWER_pred\"], \n",
    "                 index = [\"NO_SUNFLOWER_true\", \"SUNFLOWER_true\"]\n",
    "                  )\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "\n",
    "\n",
    "## CLASSIFICATION REPORT ##\n",
    "###########################\n",
    "\n",
    "print(\"######   CLASSIFICATION REPORT (SUNFLOWER)   ######\\n###################################################\\n\")\n",
    "print(classification_report(y_true, y_pred, \n",
    "                            target_names = [\"NO SUNFLOWER IMAGES\", \"SUNFLOWER IMAGES\"]))\n",
    "\n",
    "print(\"CONFUSION MATRIX VALUES\", \"TN:\",TN, \"FP:\", FP, \"FN:\", FN, \"TP:\", TP)\n",
    "\n",
    "SUNFLOWER_CONFUSION_MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Precision-Recall Curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the performance of our model by plotting the Precision-Recall Curve. Precision-Recall Curve is typically used in binary classification to study the output of a classifier.   \n",
    "The Precision-Recall Curve shows the trade-off between precision and recall for different threshold.    \n",
    "A high area under the curve represents both high recall and high precision. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).  A perfect skill classifier has full precision and recall with a dot in the top-right corner.   \n",
    "If we are interested in a threshold which results in the best balance of precision and recall, then this is the same as finding the threshold that optimize the F1 score.      \n",
    "So, we can also plot the point corresponding to the OPTIMAL THRESHOLD (MAX F1 SCORE) on the precision-recall curve.    \n",
    "The idea is that, once found this optimal threshold, it could then be used when making probability predictions in the future that must be converted from probabilities to class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRECISION-RECALL CURVE AND OPTIMAL THRESHOLD ##\n",
    "##################################################\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, pred_prob)      # precision-recall curve\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc_score = auc(recall, precision)\n",
    "\n",
    "# summarize scores\n",
    "print(\"\\nF1 SCORE:\", f1, \"  AUC SCORE:\" ,auc_score)\n",
    "\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('\\nBest Threshold=%f, F1-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "# plot the precision-recall curves\n",
    "no_skill = len([ i for i in y_true if i == 1]) / len(y_true)                   # no-skill model\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Model')\n",
    "plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='MAX F1-SCORE')  # point max f1-score\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on single image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to test our Custom Classifier on a single image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/pasquale/CUSTOM_OBJECT_CLASSIFICATION_VGG16/\"             # image loading path\n",
    "\n",
    "image_filename = \"sunflower_img_10.jpg\"                                      # filename\n",
    "\n",
    "\n",
    "## IMAGE LOADING AND PREPROCESSING ##\n",
    "#####################################\n",
    "\n",
    "img = load_img(\n",
    "               path + image_filename,             # image filename\n",
    "               target_size=(224,224)              # load image with a specific size \n",
    "               ) \n",
    "\n",
    "img = img_to_array(img)                           # convert the pixels to a numpy array\n",
    "\n",
    "height, width, channels = img.shape               # retrieve height, width and channels of the image\n",
    "\n",
    "img = img.reshape((1, height, width, channels))   # reshape the image to add an extra dimension\n",
    "                                                  # (extra dimension is number of samples)\n",
    "\n",
    "img = preprocess_input(img)                       # preprocess the image to use as input into the network\n",
    "\n",
    "\n",
    "## PREDICTION ##\n",
    "################\n",
    "\n",
    "prediction_prob = final_vgg16_model.predict(img)        # model prediction on single image\n",
    "\n",
    "print(image_filename, \" PROBABILITY OF SUNFLOWER IN THE IMAGE:\", prediction_prob[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...finally, don't forget to clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAR GPU MEMORY ##\n",
    "######################\n",
    "\n",
    "K.clear_session()\n",
    "cuda.select_device(0)            # select specific GPU device \n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
